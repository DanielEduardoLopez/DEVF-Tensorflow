{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K30p_UI0xK0c"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Challenge 2 (Solución)\n",
        "Objetivo: Repetir el ejercicio de la clase pero con el dataset de Fashion MNIST.\n",
        "\n",
        "  1. Importa el dataset de Fashion MNIST desde Keras como vimos en clase. \n",
        "     Puedes utilizar la documentación como referencia: https://keras.io/api/datasets/fashion_mnist/\n",
        "  2. Escribe el código para normalizar el dataset.\n",
        "  3. Construye una red neuronal para crear un clasificador para ese dataset. Recuerda que tenemos 10 clases diferentes de ropa en el mismo.\n",
        "    a. Reutilizar la capa Flatten como entrada de la red neuronal.\n",
        "    b. Prueba agregar más de 1 capa oculta.\n",
        "    c. Prueba a poner diferentes cantidades de neuronas para cada capa oculta.\n",
        "  4. Añade la capa de salida con 10 neuronas y con la función de activación adecuada para un clasificador multiclase.\n",
        "  5. Escribe el código para crear un callback que detenga el entrenamiento cuando alcances un 99%.\n",
        "  6. Completa el código para entrenar el modelo.\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def train_mnist():\n",
        "    # Create a class to build the required callback to stop training\n",
        "    # YOUR CODE SHOULD START HERE\n",
        "    class MyTrainer(tf.keras.callbacks.Callback):\n",
        "      def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')>0.99): # { 'accuracy': 0.999 }\n",
        "          print('Se ha alcanzado el 99% de precisión')\n",
        "          self.model.stop_training = True\n",
        "    # YOUR CODE SHOULD END HERE\n",
        "\n",
        "    # Load Fashion MNIST dataset with TensorFlow Datasets (or with Keras,\n",
        "    # it's your choice)\n",
        "    # REMEMBER: You need to normalize your images to 0 to 1 scale\n",
        "\n",
        "    # YOUR CODE SHOULD START HERE\n",
        "    # ---- Forma con Keras ----\n",
        "    # Más info en: https://keras.io/api/datasets/fashion_mnist/#load_data-function\n",
        "    # Cargar el dataset:\n",
        "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "    type(fashion_mnist)\n",
        "    (x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "    # Normalizar mis datos\n",
        "    x_train = x_train / 255.0\n",
        "    x_test = x_test / 255.0\n",
        "\n",
        "    \"\"\"\n",
        "    # ---- Forma con TensorFlow Datasets ----\n",
        "    # Más info en: https://www.tensorflow.org/datasets/keras_example\n",
        "    (ds_train, ds_test), ds_info = tfds.load('mnist',\n",
        "                                   split=['train', 'test'],\n",
        "                                   shuffle_files=True,\n",
        "                                   as_supervised=True,\n",
        "                                   with_info = True)\n",
        "\n",
        "    # Build a training pipeline\n",
        "    def normalize_img(image, label):\n",
        "      # Normalizes images: `uint8` -> `float32`.\n",
        "      return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "    ds_train = ds_train.map(\n",
        "        normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds_train = ds_train.cache()\n",
        "    ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "    ds_train = ds_train.batch(128)\n",
        "    ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    # Build an evaluation pipeline\n",
        "    ds_test = ds_test.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds_test = ds_test.batch(128)\n",
        "    ds_test = ds_test.cache()\n",
        "    ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
        "    \"\"\"\n",
        "    # YOUR CODE SHOULD END HERE\n",
        "\n",
        "    # Create an instance of your callback\n",
        "    # YOUR CODE SHOULD START HERE\n",
        "    callbacks = MyTrainer()\n",
        "    # YOUR CODE SHOULD END HERE\n",
        "    \n",
        "    model = tf.keras.models.Sequential([\n",
        "        # YOUR CODE SHOULD START HERE\n",
        "        tf.keras.layers.Flatten(), # Capa de aplanamiento\n",
        "        tf.keras.layers.Dense(128, activation='relu'), # Capa densa de 128 neuronas\n",
        "        tf.keras.layers.Dense(10, activation='softmax') # Capa de salida de 10 neuronas\n",
        "        # YOUR CODE SHOULD END HERE\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # model fitting\n",
        "    history = model.fit(# YOUR CODE SHOULD START HERE\n",
        "                        # ---- Forma con TensorFlow Datasets ----\n",
        "                        # ds_train,\n",
        "                        # validation_data=ds_test,\n",
        "                        # ---- Forma con Keras: ----\n",
        "                        x_train,\n",
        "                        y_train,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=10,\n",
        "                        callbacks=[callbacks]\n",
        "              # YOUR CODE SHOULD END HERE\n",
        "    )\n",
        "    return history.epoch, history.history['accuracy'][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxFO6Ra11p0m",
        "outputId": "5e5a4f12-950b-4b54-cbde-2b1d4c98ff57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2538 - accuracy: 0.9279\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1114 - accuracy: 0.9675\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0776 - accuracy: 0.9767\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0574 - accuracy: 0.9825\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0447 - accuracy: 0.9867\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0345 - accuracy: 0.9896\n",
            "Epoch 7/10\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9919Bien hecho, novato. Alcanzaste el 99% de precisión\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0276 - accuracy: 0.9919\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "([0, 1, 2, 3, 4, 5, 6], 0.9918666481971741)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_mnist()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
